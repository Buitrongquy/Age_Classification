{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yJu2nyNmdI_Pl8r4t6cfanhJJLlBJ92B",
      "authorship_tag": "ABX9TyNn30yxsGYdBpBjb2ZXmJ8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buitrongquy/Age_Classification/blob/main/Age_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWN2MeqF4_AX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "#dataset = Dataset.list_files(\"/content/drive/MyDrive/FILE/Face_data/UTKFace/*.jpg.chip.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.list_files(\"/content/drive/MyDrive/FILE/Face_data/train_dataset/*.jpg\")\n",
        "val_dataset = tf.data.Dataset.list_files(\"/content/drive/MyDrive/FILE/Face_data/val_dataset/*.jpg\")\n",
        "test_dataset = tf.data.Dataset.list_files(\"/content/drive/MyDrive/FILE/Face_data/test_dataset/*.jpg\")"
      ],
      "metadata": {
        "id": "ZGyJ6Rrv4JSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def get_label(file_path):\n",
        "  name = tf.strings.split(file_path,'/')[-1]\n",
        "  name = tf.strings.split(name,'.')[0]\n",
        "  age = int(tf.strings.split(name,'_')[2])\n",
        "  group = (age - 1)//5\n",
        "  label = list(np.zeros(24, dtype=np.float32))\n",
        "  for i in range(24):\n",
        "    if i == group:\n",
        "      label[i] = 1.0\n",
        "  return tf.convert_to_tensor(label)"
      ],
      "metadata": {
        "id": "hZMcFLYT6cP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in train_dataset.take(10):\n",
        "  print(get_label(path))\n"
      ],
      "metadata": {
        "id": "8j4RXVF46e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5820c484-9848-4da9-be67-7bc1c9a39780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(24,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(file_path):\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.io.decode_jpeg(img, channels=1)\n",
        "  img = tf.image.resize(img, [100,100])\n",
        "  img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "  label = get_label(file_path)\n",
        "\n",
        "  return img, label\n",
        "\n"
      ],
      "metadata": {
        "id": "okr-UlCD6giC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = Dataset.list_files(\"/content/drive/MyDrive/FILE/Face_data/UTKFace/*.jpg.chip.jpg\")\n",
        "train_dataset = train_dataset.map(preprocessing).shuffle(13000).batch(32).prefetch(2)\n",
        "val_dataset = val_dataset.map(preprocessing).batch(32).shuffle(2000)\n",
        "test_dataset = test_dataset.map(preprocessing).batch(32).shuffle(2000)"
      ],
      "metadata": {
        "id": "hH6NMQ8ZRUyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.Input(shape=(100,100,1))\n",
        "\n",
        "layer_1 = tf.keras.layers.Conv2D(10, 1, padding='same', activation='relu')(input)\n",
        "\n",
        "layer_2 = tf.keras.layers.Conv2D(5, 1, padding='same', activation='relu')(input)\n",
        "layer_2 = tf.keras.layers.Conv2D(5, 3, padding='same', activation='relu')(layer_2)\n",
        "\n",
        "layer_3 = tf.keras.layers.Conv2D(5, 1, padding='same', activation='relu')(input)\n",
        "layer_3 = tf.keras.layers.Conv2D(5, 5, padding='same', activation='relu')(layer_3)\n",
        "\n",
        "layer_4 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=(1,1), padding='same')(input)\n",
        "layer_4 = tf.keras.layers.Conv2D(10, 1, padding='same', activation='relu')(layer_4)\n",
        "\n",
        "inception = tf.keras.layers.concatenate([layer_1, layer_2, layer_3, layer_4], axis = 3)\n"
      ],
      "metadata": {
        "id": "1SNTnKqTmiTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = tf.keras.layers.Flatten()(inception)\n",
        "desen = tf.keras.layers.Dense(800, activation='relu')(flatten)\n",
        "desen = tf.keras.layers.Dense(200, activation='relu')(desen)\n",
        "output = tf.keras.layers.Dense(24, activation='softmax')(desen)"
      ],
      "metadata": {
        "id": "JnLs-Jf0jbLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(input,output)"
      ],
      "metadata": {
        "id": "Hf6QvN2W3o8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvCKZNqIAhxH",
        "outputId": "f1de4625-bbf9-4180-e299-9bf00f415d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 100, 100, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 100, 100, 5)          10        ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 100, 100, 5)          10        ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 100, 100, 1)          0         ['input_1[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 100, 100, 10)         20        ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 100, 100, 5)          230       ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 100, 100, 5)          630       ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 100, 100, 10)         20        ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 100, 100, 30)         0         ['conv2d[0][0]',              \n",
            "                                                                     'conv2d_2[0][0]',            \n",
            "                                                                     'conv2d_4[0][0]',            \n",
            "                                                                     'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 300000)               0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 800)                  2400008   ['flatten[0][0]']             \n",
            "                                                          00                                      \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 200)                  160200    ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 24)                   4824      ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 240166744 (916.16 MB)\n",
            "Trainable params: 240166744 (916.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "GP6UwouKBQkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, weight_decay=1e-3)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
      ],
      "metadata": {
        "id": "rMpiX49PRbud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/FILE/Face_data/model.h5'\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=8, verbose=1, mode='max',restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=5, verbose=1, mode='max', min_delta=1e-2, min_lr=1e-9)\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=path, monitor='val_acc', verbose=1, save_best_only=True, mode='max' )"
      ],
      "metadata": {
        "id": "AGhLg5u6-sUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [earlystopping, reduce_lr, checkpointer]"
      ],
      "metadata": {
        "id": "HHjfhq8BS3RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,\n",
        "          steps_per_epoch=len(train_dataset),\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps=len(val_dataset),\n",
        "          callbacks=callbacks,)"
      ],
      "metadata": {
        "id": "TTpXAv4GTG0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8731171c-1a74-4bd9-ffa1-b0415fc0f68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0466 - acc: 0.9947\n",
            "Epoch 1: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 54s 105ms/step - loss: 0.0466 - acc: 0.9947 - val_loss: 2.2870 - val_acc: 0.7856 - lr: 5.0000e-05\n",
            "Epoch 2/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9926\n",
            "Epoch 2: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 52s 102ms/step - loss: 0.0532 - acc: 0.9926 - val_loss: 2.3191 - val_acc: 0.7951 - lr: 5.0000e-05\n",
            "Epoch 3/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.9948\n",
            "Epoch 3: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 51s 97ms/step - loss: 0.0403 - acc: 0.9948 - val_loss: 2.2522 - val_acc: 0.7932 - lr: 5.0000e-05\n",
            "Epoch 4/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0482 - acc: 0.9939\n",
            "Epoch 4: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 51s 98ms/step - loss: 0.0482 - acc: 0.9939 - val_loss: 2.1680 - val_acc: 0.7936 - lr: 5.0000e-05\n",
            "Epoch 5/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.9945\n",
            "Epoch 5: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 50s 97ms/step - loss: 0.0451 - acc: 0.9945 - val_loss: 2.2485 - val_acc: 0.7913 - lr: 5.0000e-05\n",
            "Epoch 6/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0442 - acc: 0.9950\n",
            "Epoch 6: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 55s 108ms/step - loss: 0.0442 - acc: 0.9950 - val_loss: 2.1621 - val_acc: 0.7970 - lr: 5.0000e-05\n",
            "Epoch 7/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0461 - acc: 0.9948\n",
            "Epoch 7: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 52s 99ms/step - loss: 0.0461 - acc: 0.9948 - val_loss: 2.2154 - val_acc: 0.7932 - lr: 5.0000e-05\n",
            "Epoch 8/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9946\n",
            "Epoch 8: val_acc did not improve from 0.79702\n",
            "383/383 [==============================] - 53s 99ms/step - loss: 0.0501 - acc: 0.9946 - val_loss: 2.3028 - val_acc: 0.7924 - lr: 5.0000e-05\n",
            "Epoch 9/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0500 - acc: 0.9944\n",
            "Epoch 9: val_acc improved from 0.79702 to 0.80008, saving model to /content/drive/MyDrive/FILE/Face_data/model.h5\n",
            "383/383 [==============================] - 163s 390ms/step - loss: 0.0500 - acc: 0.9944 - val_loss: 2.2119 - val_acc: 0.8001 - lr: 5.0000e-05\n",
            "Epoch 10/10\n",
            "383/383 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.9952\n",
            "Epoch 10: val_acc did not improve from 0.80008\n",
            "383/383 [==============================] - 53s 102ms/step - loss: 0.0477 - acc: 0.9952 - val_loss: 2.2426 - val_acc: 0.7966 - lr: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e7620672620>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.saving.load_model('/content/drive/MyDrive/FILE/Face_data/model.h5')"
      ],
      "metadata": {
        "id": "HqX856-IREs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJZqmiGt5Sbl",
        "outputId": "c2ae9205-0a32-4f87-96c2-847cacb9a413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/82 [==============================] - 483s 12ms/step - loss: 2.3949 - acc: 0.7721\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3948867321014404, 0.7721374034881592]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}